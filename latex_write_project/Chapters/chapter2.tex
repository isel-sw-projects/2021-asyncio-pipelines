% 
%  chapter2.tex
%  ThesisISEL
%  
%  Created by Matilde Pós-de-Mina Pato on 2012/10/09.
%
\chapter{State of the Art}
\label{cha:users_manual}

This section, aims to show the background and the current state of the art on the subject related with asynchronous pipeline operations involving asynchronous data flows.  
On the section \ref{sec:related_work}, will be made an overview on previously developed work made on this subject, then, on section \ref{sec:async_concepts}, will be made a characterization of the key concepts related to it. By last, on section \ref{sec:state_of_the_art}, are presented and explained several technologies representative of the state of the Art on how asynchronous operation pipe lining are implemented in different programming realities, e.g. on Kotlin, JAVA and C\#. 


% ================
% = Related work =
% ================
\section{Background} % (fold)
\label{sec:related_work}

% Initially, when computers had a single processing unit, the networks only allowed the exchange of few bytes per second and the data servers didn't had the responsiveness requirements that are mandatory today; software computational systems were simpler, in the sense that operations were mostly made in a single execution thread. 
% The servers design, were made without many concerns about availability under demand pressure or computer resource optimization. 
% Consequently, operations that required intensive IO interactions or data request from an external sources, were mostly blocking, non-flexible in terms of responsiveness and interoperability. 

From the end of 80’s to the beginning of the 2000’s, with the acceleration of Moore's Law in hardware and network bandwidth development; the creation of the internet as we know today through the wide spread of use of the HTTP protocol, the necessity of high responsiveness and efficient systems started to grow. This increase in demand of new ways to handle data efficiently and the wide spread of multicore processors created the necessity of the implementation of new software frameworks models that can handle data efficiently taking in account the multithread systems and the asynchronous characteristics of data receiving throw network. 

Taking the wave initiated by the Gang of Four in \citep{gof}, where 23 patterns were compiled to deal with object-oriented problems; a group of researchers wrote a paper \citep{proactor}, where they identify the characteristics that high available systems must have, and how the use of asynchronous IO pipe design patterns can help to achieve these characteristics, as described bellow:
\begin{itemize}
	\item Concurrency - The server must process multiple client requests simultaneously.\\
	\item Efficiency - The software design must be built aiming the use the least hardware resources as possible. \\
	\item Simplicity - The code of the solution must be easy to understand, modular and avoid own built design patterns as possible. \\
    \item Adaptability - The system must be totally decoupled from client implementations, allowing it to be easily used by any client independently of the underlying technologic realities. To achieve this, may be used standards e.g. \cite{REST} or SOAP.\\
\end{itemize}

To achieve some of these properties, the authors propose the \textit{Proactor Pattern} \citep{proactor}. In their opinion, traditional concurrency models, until that date, failed to fully achieve the enumerated properties.

On the other side, before presenting the \textit{Proactor Pattern}, are identified two major existing non-blocking models, namely: \textit{multithreading} and \textit{reactive event dispatching}. 

On multithreading, the paper refers that one of the most direct solution of this approach, is the handling of multiple requests by creating a new thread every request. Each request will then be fully processed and the recently created thread is then be disposed after the work is done. 

This solution has several serious issues. Firstly, creating a new thread per request is highly costly in terms of computational resources,
because are involved context switches between user and kernel modes; secondly, must be taken in account synchronization to maintain data integrity.
Then, the authors warn about the fact that the IO retrieved data is mainly memory-mappped, which rises the question: What happens when the data obtained through IO becomes greater than the system memory can hold? The system stalls until more memory becomes available!? One possible solution is asynchronous pipelines that will be discussed ahead in this dissertation.
On last, if the server receives a high demand of requests, the server easily blocks in the process of creating and disposing threads. 

To avoid this issue, the authors, recommended the use of dynamic thread pools to process requests, where each request will be linked to a pre-existing thread, avoiding all the overhead of creating and disposing a thread per request;
however, issues related with memory-mapping and overhead due to the switching of data between different threads maintains. 

Another traditional concurrency model identified by the authors of the paper, is the \textit{Reactive Synchronous Event Dispatching}. In this model, a \textit{Dispatcher}, with a single thread in a loop, is constantly listening requests from clients and sending work requests to an entity named \textit{Handler}. 
The \textit{Handler}, will then process the IO work Synchronously and request a connection to the client in the \textit{Dispatcher}. When the requested connection is ready to be used, the \textit{Dispatcher} notifies the \textit{Handler}. After the notification, the \textit{Handler} asynchronously sends the data, that is being or has been obtained through IO, to the client.\\
Although the authors identifying that this approach is positive, because decouples the application logic from the dispatching mechanisms, besided with the low overhead due the use of a single thread, the authors identify several drawbacks with this approach. 
Firstly, since IO operation are synchronous, the code for this approach is complex because must be set in place mechanisms to avoid IO blocking through hand off mechanisms. 
Then, if a request processing blocks, the processing of another requests may be impacted. 

To keep the positive points but mitigating the identified issues of previous approaches, is suggested the \textit{Proactor Pattern}. 
This pattern is very similar to the \textit{Reactive Synchronous Event Dispatching}, however, after the requests processed by a single threaded \textit{Completion dispatcher}, 
the IO work is then dispatched asynchronously to the underlying OS IO subsystems, where multiple requests can be processed simultaneously. 
For the result to be retrieved, is previously registered a callback in the \textit{Completion Dispatcher} and the OS has the responsibility to queue the finished result in a well known place. 

Finally, the \textit{Completion Dispatcher} has the responsibility to dequeue the result placed by the OS and call the correct previously registered callback. 
With this, this model creates a platform that provides: decoupling between application and processing mechanisms,
offers concurrent work without the issues inherent with the use of threading mechanisms and since IO is managed by the OS subsystems, is avoided code complexity in handling possible blocking and scheduling issues.  

The \textit{Proactor Pattern}, creates the ground for several models used by modern platforms that use a reduced number of threads to process client requests and parallel mechanisms to do the heavy work in the background. Some of these technologies, are, for example: \textit{Javascript NODE.JS}, \textit{Spring Webflux}, \textit{vertx} and others.

From what was explained until now, is evident the tendency followed by software architects in terms of asynchronous processing from non-reactive to event driven approaches and trying to make the code simpler and easier to maintain. Initially the systems were non-reactive, where each request had to be processed in a 
specific thread and that thread blocked until something got ready to go further. The code was usually very complex and hard to maintain. 
Then, with the asynchronous systems based on events with the introduction of callback systems inspired in patterns like the \textit{Reactor} or \textit{Proactor} the software design started to become more event driven, allowing the servers to be more efficient in responsiveness, resources optimization and code easier to read and maintain by the average programmer.

However, are some limitations in these asynchronous models. For example, if the data to be processed is bigger than the memory available at a given moment or if the data to be calculated is from a source that produces data at a constant rate that must be processed in real time, these models work badly.  
The traditional models fail to comply these objectives because are mostly eager by design or not comply with the notion of a continuous source of information that requires to be processed in real time.
Taken this in account, projects like project Reactor, Asynchronous Enumerable provided by Microsoft or papers like \cite{LAZYVSEAGER}, try to deal with these issues, by providing API's that merge the concepts of Fluent API's, functional programming and code syntax that tries to resemble synchronous code, being the complexity inherent with asynchronous models implementations hidden from the programmer since the asynchronous events are treated like, for example, a \texttt{Stream} in JAVA would be treated.

\clearpage



% ====================
% = Folder Structure =
% ====================
\section{Asynchronous flow key concepts and design alternatives} % (fold)
\label{sec:async_concepts}



With the development of several approaches related to asynchronous IO processing, and with the growing necessity to build a name set of properties that simplify the description of asynchronous systems, a dictionary
of properties, concepts and design alternatives started to grow by itself. In the following, are discussed several of the concepts related with asynchronous data flow, namely:

\subsection{Synchronous versus Asynchronous}
	Before explaining more terms related with asynchronous data flow, it's important to clarify what is synchronous and asynchronous in programming. 
	
	Asynchronous in programming, is a call to a function or routine that returns immediately, not blocking the caller until the operation is finished. The operation processing, will be completely independent from the caller execution process and can even be done in another machine. This way, the caller is freed to do more work, even to start \texttt{N} more operations in parallel. 
	
	Meanwhile, a call to a synchronous function or routine, blocks the caller until the operation finishes. In this case, the caller has to wait for the completion of the synchronous operation before going forward, which limits the program efficiency if parallelism is applicable.
	To better visualize what was explained, we have the following examples: 
	

\begin{center}
	\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
	\begin{minipage}{.48\textwidth}
	\begin{lstlisting}[
		escapeinside={(*}{*)},
			caption={Asynchronous call example},
			label={lst-top5-linq}
	]
HttpClient client = HttpClient.newHttpClient();

HttpRequest request = HttpRequest
	.newBuilder(URI.create("SOME MOVIE API"))...

Task futureResponse = client
	.sendAsync(request, new JsonBodyHandler<>(DTO.class)) 
	.thenAccept(res -> {
		Console.WriteLine( res.title);
); 

Console.WriteLine("prints something")

client.Wait();

//OUTPUT:
//prints something
//movie title
		
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{.48\textwidth}
\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
\begin{lstlisting}[
	escapeinside={(*}{*)},
	columns=fullflexible,
	showstringspaces=false,
		caption={Synchronous call example},
		label={lst-top5-async}
]
HttpClient client = HttpClient.newHttpClient();

HttpRequest request = HttpRequest.newBuilder(
	URI.create("SOME URL"))
	.header("accept", "application/json")
	.build();

HttpResponse<Supplier<DTO>> res = 
	client.send(request, new JsonBodyHandler<>(DTO.class))//synchronous

Console.WriteLine(res.title);

Console.WriteLine("prints something")

//OUTPUT:
//movie title
//prints something

		\end{lstlisting}
	\end{minipage}
\end{center}

	
	As we can see, in the synchronous call example, the operation return only happens after the whole subsequent remote operation is finished, consequently, the caller operation is dependent from several variables to go forward e.g. : HTTP messaging latency, remote server operation speed or bandwidth issues. 
	This causes that the processing of the next code statements to happen only after the synchronous IO call.

	Meanwhile, in the asynchronous operation call, the return happens immediately after the call, however, the processing inherent with that operation will start just when the subsystem that handles the asynchronous function is ready to process that work. For example, when the OS is ready to process the received responses from a remote server that handled the operation.
	In this case, the statement right after the asynchronous call is processed before the asynchronous operation. Allowing the IO asynchronous operation to processed outside the program scope and avoiding any block of the main program.


	\subsection{Push vs Pull}
	Another concept important to understand how asynchronous data flow is handled in programming, is the \textit{Pull} and \textit{Push} processing patterns.
	In \textit{Pull} pattern, usually, exists a source of data and the program iterates over that source to operate over each item. 
	
	On the other hand, in the \textit{Push} pattern, the items of the data source are "Pushed" to a routine that will operate over that item.
	To help to assimilate what was just explained, we have the following example:


	\begin{center}
		\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
		\begin{minipage}{.48\textwidth}
		\begin{lstlisting}[
			escapeinside={(*}{*)},
				caption={Example of Pull data handling patterns},
				label={lst-top5-linq2}
		]
Flowable<Long> flow = Flowable
	.interval(1, TimeUnit.SECONDS);

Iterator<Long> iterator = 
	flow.blockingIterable().iterator();

while (iterator.hasNext()) 
	System.out.println(iterator.next());
		
		\end{lstlisting}
		\end{minipage}
		\hfill
		\begin{minipage}{.48\textwidth}
		\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
		\begin{lstlisting}[
			escapeinside={(*}{*)},
			columns=fullflexible,
			showstringspaces=false,
				caption={Example of Pull data handling patterns},
				label={lst-top5-dot-net-imp}
		]
Flowable<Long> flow = Flowable
	.interval(1, TimeUnit.SECONDS);

flow.blockingSubscribe(System.out::println);

		\end{lstlisting}
		\end{minipage}
	\end{center}


	As we can see, in the pull pattern, the items are "pulled" from a data source through an iteration mechanism. 
	
	In contrast with that, in the \textit{Push} pattern, items are pushed to a consumer through a supplier.


	\subsection{Hot versus Cold}
	
	Another property that must be taken in account when handling with \textit{Reactive Streams} or asynchronous data processing in general, is the nature of the data flow. 
	There are two main adjectives to name a data flow, \texttt{Hot} or \texttt{Cold}. 

	A \texttt{Cold} data flow, is a flow of information that is produced just when the stream pipeline in subscribed by an observer. In this case, the producer only starts sending/producing data when someone is interested in the data from that source. 
	For example, when program uses a IO mechanism to lazily retrieve a sequence of words from a database, the IO mechanism will only start sending information just when a consumer subscribes that data flow. Usually, the data is sent to the consumer in unicast.
	
	On the other hand, in a \texttt{Hot} data flow, the data is produced independently of existing any observer to that information. This mechanism usually work in broadcast and the data is continuously produced and sent to possible observers.
	In this case, when an observer subscribes to a publisher, exists the possibility of data items being already lost to that publisher while in the \texttt{Cold} flow, the consumer usually receives all items that were produced by the source.
	In the following examples, a number is produced each 100 milliseconds:


	\begin{center}
		\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
		\begin{minipage}[t][][b]{.46\textwidth}
		\begin{lstlisting}[
			escapeinside={(*}{*)},
				caption={Cold flow example},
				label={lst-top5-java-cold}
		]
ConnectableFlowable<Long> hot = Flowable
	.intervalRange(0, 100, 0, 100, TimeUnit.MILLISECONDS)
	.publish();
flux.connect(); 
Thread.sleep(1000);
flux.blockingSubscribe(System.out::println

//output:
//2
//3
//4
//
		\end{lstlisting}
		\end{minipage}
		\hfill
		\begin{minipage}{.48\textwidth}
		\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
		\begin{lstlisting}[
			escapeinside={(*}{*)},
			columns=fullflexible,
			showstringspaces=false,
				caption={Hot flow example},
				label={lst-top5-java-cold}
		]
Flowable<Long> cold = Flowable.interval(100, TimeUnit.MILLISECONDS);
Thread.sleep(1000);
cold.blockingSubscribe(System.out::println); 
//Output:
//1
//2
//3
		\end{lstlisting}
		\end{minipage}
	\end{center}


	As we can see, in the \texttt{Hot} data flow example, the items are emitted from the moment the producer is created, independently of existing any subscriber or observer attached to that publisher. Notice that when a consumer is subscribed to the publisher, 1 seconds after the emition started, the numbers from 0 to 10 were not printed.
	
	In the \texttt{Cold} example, the producer only emits data when a subscription is done, and because of that, all the produced numbers were printed, in contrast with what happen in \texttt{Hot} stream, where data loss are almost certain. 
	\clearpage
	\subsection{Cancelable} 
	As already stated above, asynchronous operations may run outside the main program scope. 
	This implies, that the main program loses visibility and control on what happens in the asynchronous operation contexts.
	Because of that, exists the need to put in place mechanisms of control that allow the main program to maintain control over an asynchronous operation to, for example, cancel the operation or put in place finishing logic that allow, for example: resource disposing, logging, decisions etc...

	These mechanisms, are many times done through the concept of \textit{cancelables}. 
	Usually, a cancelable, is an entity that represents an operation that can canceled from an external entity, or, an entity that allows to set logic when an operation finishes by any reason.
 
	In C\#, a cancelable is an interface implemented by objects that represent asynchronous operations and provides the means to cancel asynchronous operations, on the fly. 
	This is achieved through a mechanism named: \texttt{CancellationToken}, that is used to pass information through different execution threads. 
	
	In RxJava, a \texttt{Cancelable}, is a functional interface with the method \texttt{cancel()}. Then, the \texttt{Cancelable} can be associated to a data source representation, the \texttt{Observable}, by calling the method \texttt{Observable.setCancelable(Cancelable)}. 
	When the \texttt{Observable} finishes or is canceled for any reason, the method \texttt{Cancelable.cancel()}\\ will be called. 
	This way,  proper logic is put in place to handle an asynchronous operation cancelation.
	
	As we saw, these two concepts of cancelable diverge. One, provides the means to cancel an operation on the fly and gives some control over the operation cancelation; the other, provides the means to control an operation cancelation independently of how it was cancelled.
	
	\clearpage
	\subsection{Error Handling}  
	In synchronous environments, usually, when something goes wrong, the way to handle an error in the majority of cases its by throwing an exception and propagate it until the proper code handles it, usually  in a try/catch block. 
	However, in cases when exists an asynchronous operation or when a continuous stream of data items are being received, that way of dealing with an error can imply several issues, e.g: exceptions not reaching main program, log losing or asynchronous flow blockage. 
	
	Since log losing or blocking a whole operation because of a badly handled error is unacceptable, the best way to deal with errors in asynchronous data flow it is to isolate the error. This way, the flow processing may continue in parallel while the error is properly handled.
	
	The best way to handle this kind of errors, it is to have proper callbacks that are called when an error occurs on the stream item. This way, a function can handle the error properly, without the necessity to blocking any data stream processing, if avoidable and the proper logging and any additional measure to handle it can be put in place.
	\clearpage
	

	\subsection{Intrinsic Keywords} 
	
	As already stated, asynchronous code is tendentiously harder to understand because, in opposition with what happens in synchronous environments, the operations inherent with the sequence of programming statements operations may not happen chronologically ordered. 
	Because of that, many times it is difficult read, debug and sustain asynchronous software. 

	For that reason, many languages started to add syntax techniques that allow the programmer to build asynchronous code that resembles the synchronous syntax.
	Under the hoods, the virtual machines that sustain these syntax mechanisms, handle the code bounded with that 'intrinsic words' and builds asynchronous routines that the programmer will not be aware of;
	being this a way to abstract the programmer from the complexity of handling and sustaining complex asynchronous code. 

	One example of \textit{intrinsic words} mechanisms, is the \texttt{async...await} keywords implemented in \textit{Microsoft's .NET C\#} and in \textit{javascript}. 
	
	In the next example we can see an example of these keywords being used:

	\begin{center}
		\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
		\begin{lstlisting}[
			escapeinside={(*}{*)},
				caption={Intrisic words .NET C\#},
				label={lst-top5-linq3}
		]
static async Task Main(string[] args)
{
	IAsyncEnumerable<int> enumerable = FetchItems(1000);
	int i = 0;
	await foreach (var item in enumerable)
	{
		if (i++ == 10){ break;}
	}
}

static async IAsyncEnumerable<int> FetchItems(int delay)
{
	int count = 0;
	while(true)
	{
		await Task.Delay(delay);
		yield return count++;
	}
}
		\end{lstlisting}
	\end{center}


	Where, for example, we can observe in the line 16, a call to an asynchronous operation, and, by adding the keyworkd \texttt{await}, the next statement although being a call to an asynchronous operation, the code statement order looks like it is from synchronous set of instructions. 
	
	Additionally, the use of \texttt{async...await} in .NET, for example, simplifies error handling in asynchronous code. Instead of use a callback to handle an error, by using \texttt{async...await} the error can be handled by just using a simple try/catch block. 

	
	To better visualize the advantage of using intrinsic words in asynchronous code, on the next example, we can see a code comparison in ECM6 Javascript, with and without the use of intrinsic words in asynchronous code. 
	In the next example, it is possible to observe a decrease of code complexity and increment of readability where is used the "syntax sugar" provided by the 'yield' return. 
	
	The example using promises is purposefully made with a "Pyramid of Doom" code to accentuate a difficulty of reading asynchronous if is made without any concern with readability.
	
	\begin{center}
		\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
		\begin{minipage}[t][][b]{.46\textwidth}
		\begin{lstlisting}[
			escapeinside={(*}{*)},
				caption={Javascript Example with promises},
				label={lst-top5-js-example}
		]
function ourImportantFunction(callback) {
	task1(function(val1) {
		task2(val1, function(val2) {
			task3(val2, callback);
		});
	});
}
		\end{lstlisting}
		\end{minipage}
		\hfill
		\begin{minipage}{.48\textwidth}
		\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
		\begin{lstlisting}[
			escapeinside={(*}{*)},
			columns=fullflexible,
			showstringspaces=false,
				caption={Javascript syntax sugar},
				label={lst-top5-js-ss}
		]
function ourImportantFunction() {
	
	var val1 = yield task1();
	
	var val2 = yield task2(val1);
	
	var val3 = yield task3(val2);

	return val3;
});

		\end{lstlisting}
		\end{minipage}
	\end{center}

As we can see, with the use of \texttt{yield} keyword, the code that uses a result of several asynchronous operation, instead of being used in a "Matrioska Dool" type of code, with a code made with a chain of callback results; 
the simple use of a intrisic keyword like \texttt{yield} simplifies the code a lot. Making the code previously hard to read in a easier code to understand and maintain.  
	
	\clearpage

	\subsection{Back-pressure} 

	When the \textit{pull} method is used to retrieve items from a source, the producer retrieves only the items it can process in the given time. 
	
	However, when the \textit{push} approach is used as data retrieval method from asynchronous flows, the producers have the initiative to push items to its consumers. 
	This can originate situations, where the producer emits items faster than the producers can handle, which can create problems like: unwanted loss of data, lack of responsiveness from consumers, etc... 
	
	To resolve these issues, were created strategies and design patterns that are commonly referred as \textit{Backpressure}.
	There are four main approaches which the majority of \texttt{Backpressure} strategies are designed from and can be resumed as: 
	
	\begin{enumerate}
		\item \textbf{DROP:} Producer drops items after a retrieving buffer gets full.
		\item \textbf{Buffer everything:} A buffer, keeps all unprocessed items that are received. Usually, this strategy is used when all received items are critical for the business development and memory managment has flexibility to handle the increase of storage needs.
		\item \textbf{Error:} An error is thrown when the buffer threshold is reached, usually all items received after the threshold is reached are discarded.
		\item \textbf{Lastest:} Only the last received item in the given moment is kept.
		\item \textbf{Missing:} No back-pressure strategy it is in place, all items that ca not be processed on arrival, are discarded.
	\end{enumerate}
	\clearpage

	
% ===================
% = Package options =
% ===================
\section{State of the Art} % (fold)
\label{sec:state_of_the_art}

In this section, we will delve into various state-of-the-art frameworks designed for asynchronous IO pipeline processing across multiple programming languages.

Initially, we explore the options available in the Java landscape in Section \ref{sec:java}. Here, we begin with an explanation of the multi-language project \textit{ReactiveX.io} and its Java implementation, \textit{RxJava}. Subsequently, we will discuss the Reactor Project, followed by an examination of non-blocking processing in the JVM, specifically through Kotlin's native \texttt{Flow} implementation.

Following Java, we shift our focus to Microsoft's .NET C\# in Section \ref{sec:csharp}. A brief mention of ReactiveX's c\# implementation precedes a deep dive into how C\# natively addresses this challenge, particularly through the implementation of \texttt{AsyncEnumerables}.

Next, we explore JavaScript's native solution to this problem, highlighting the use of asynchronous Iterables through the \textit{intrinsic keywords} \texttt{FOR AWAIT...OF} and Promises. Additionally, we refer to ReactiveX's implementation for JavaScript, RXJS.

Finally, in Section \ref{sec:tech_compare}, we provide a comprehensive overview and draw conclusions about the various technologies discussed, comparing how each approach can be utilized for different problems and objectives. We also make theoretical predictions about the potential performance of each technology under several known circumstances.

\subsection{Java}
\label{sec:java}

In the context of Java, we will explore several libraries and frameworks aimed at simplifying asynchronous data flow handling. 

The first is \textit{RxJava}, which is a Java implementation of the \textit{ReactiveX.io} project. This library uses the \texttt{Observer pattern} to handle real-time asynchronous processing with and without back-pressure. It is important to note that the ReactiveX.io project is a multi-language project, and its Java implementation, RxJava, is among the most widely used.

Next, we delve into \textit{Project Reactor}, an integral part of Spring WebFlux's non-blocking web stack. Although it uses a different approach from \textit{ReactiveX}, it still provides the same benefits, like allowing developers to work with a composable API for declarative, event-driven programming.

Lastly, we will discuss the \textit{Kotlin Flow} strategy, which is utilized in the Kotlin language but interoperable with Java. This will provide us with a perspective on how coroutine-based asynchronous data processing is implemented in the JVM environment, contrasting with the Observer pattern used by ReactiveX and Project Reactor.


\subsubsection{RxJava Library}
\label{rxjava}

Before we delve into the specifics of RxJava, it's important to discuss ReactiveX (Reactive Extensions) — the project that gave birth to it. ReactiveX is a multi-language project focusing on combining the observer pattern, iterator pattern, and functional programming techniques to make the handling of asynchronous streams of data manageable and efficient. ReactiveX libraries exist for a variety of programming languages, including JavaScript, Java, C\#, and others.

ReactiveX adopts a declarative approach to concurrency, abstracting away the complexities associated with low-level threading, synchronization, thread-safety, concurrent data structures, and non-blocking I/O. Instead, it encourages developers to focus on the composition of asynchronous data streams.

An \textit{observable} sequence in ReactiveX can emit three types of items: "next" notifications (carrying items to observers), "error" notifications (carrying error information), and "complete" notifications (signaling the end of the sequence). Observers subscribe to these observable sequences and react to whatever item they emit. The sequences are lazy; items are not pushed to observers until an observer subscribes.

Now, let's turn our attention to RxJava, the Java implementation of ReactiveX.

RxJava, an open-source project, encapsulates the \textit{Observer pattern}, the \textit{Iterator pattern}, and functional programming techniques to manage asynchronous data flow and control event sequences.

The data source/publisher of an asynchronous event stream in RxJava is represented by the \texttt{Observable} and \texttt{Flowable} classes. The key distinction is that \texttt{Flowable} supports back-pressure through various buffering strategies.

In RxJava, \texttt{Observable} and \texttt{Flowable} represent a stream of N events, while a single event is encapsulated by the \texttt{Single} class.

RxJava offers fluent APIs in \texttt{Observable} and \texttt{Flowable}, enabling operation chaining in pipelines — a feature also found in synchronous environments like Java's \textit{Stream} fluent API or .NET's Linq framework. Developers can perform stream processing operations like \texttt{filter}, \texttt{flatMap}, and \texttt{distinct} on these asynchronous event sequences, much as they would on synchronous streams in fluent APIs.

Observers/subscribers in RxJava are consumers subscribing to \texttt{Observable} through the \texttt{Observable.subscribe()} method. These consumers can be implementations of the functional interface \texttt{Consumer<T>} or the \textit{Observer} interface. The latter provides enhanced control over stream processing through error handling capabilities, which \texttt{Consumer<T>} implementations lack.

The \textit{Observer} can be regarded as an asynchronous counterpart to the Java util interface \texttt{Iterator}, as evidenced by the similarity in their interface methods.
\begin{enumerate}
    \item \texttt{onSubscription()}: This method is called immediately after a subscription is made with an \texttt{Observable}.
    \item \texttt{onNext(T item)}: This method is called when an item is emitted by the asynchronous data source.
    \item \texttt{onError()}: Contrary to the Iterator, the RxJava \textit{Observer} is equipped to support error handling. This callback is invoked when an error occurs.
    \item \texttt{onComplete()}: This method is called when the data source closes or the subscription finishes.
\end{enumerate}

Given the possible relationship between synchronous and asynchronous programming, Table \ref{tab:comparison} was developed to better visualize the correlation.


\begin{table}[h]
	\centering
	\begin{tabular}{|l|c|c|}
	\hline
	& Single Item & Multiple Items \\ 
	\hline
	Java & \texttt{T getData()} & \texttt{Iterable<T> getData()} \\ 
	\hline
	RxJava & \texttt{Single<T> getData()} & \texttt{Observable<T> getData()} \\ 
	\hline
	\end{tabular}
	\caption{Your caption}
	\label{tab:my_label}
\end{table}


\subsubsection{Reactor Library}
\label{sec:reactor_architecture}

The \textit{Project Reactor} is another part of the Spring portfolio of projects. It is designed to be a fully non-blocking foundation for Java, compliant with the Reactive Streams specification. It offers efficient demand management (back-pressure) capabilities, making it an ideal choice for scenarios involving live streams of data.

The design of Project Reactor is also based on the \textit{Publisher/Subscriber pattern}. However, instead of using \texttt{Observable}, \texttt{Flowable}, and \texttt{Single}, Project Reactor uses \texttt{Flux} and \texttt{Mono} to represent asynchronous data streams. \texttt{Flux} represents a stream of 0 to N items, while \texttt{Mono} represents a stream of 0 or 1 item.

Similar to RxJava, Project Reactor provides a variety of operators that can be used to transform, filter, combine, and manipulate data streams. This allows developers to construct intuitive instruction pipelines. 

Just like in RxJava, observers/subscribers in Project Reactor are represented by consumers that are attached to \texttt{Flux} and \texttt{Mono} via the \texttt{subscribe()} method. These consumers can either be implementations of the \texttt{Consumer<T>} functional interface or the \texttt{Subscription} interface. 
Here's a brief comparison of how Reactor relates to the conventional synchronous counterparts in Java:

\begin{center}
\begin{tabular}{ |l|c|c| }
\hline
    & Single Item & Multiple Items \\ \hline
    Java & & \\ 
    & \texttt{T getData()}  & \texttt{Iterable<T> getData()} \\
    & & \\
    \hline
    Reactor & & \\ 
    & \texttt{Mono<T> getData()} & \texttt{Flux<T> getData()} \\
    & & \\
    \hline
\end{tabular}
\end{center}

By adhering to the Reactive Streams specification and offering a wide array of operators to handle data, Project Reactor serves as a powerful tool for developing reactive, non-blocking applications in Java.

\subsubsection{Kotlin Flow}
\label{sec:kotlinflow}

Kotlin, despite being a JVM-based language, differs significantly from Java when it comes to handling asynchronous data flows. Kotlin uses coroutines, a feature natively supported in the language, to simplify asynchronous programming. This feature is used in the implementation of \texttt{Flow<T>}, Kotlin's main interface for handling asynchronous data flows.

In comparison to \texttt{Observable} and \texttt{Flux}, which are based on the Observer pattern, Kotlin's \texttt{Flow<T>} is more aligned with the principles of the \textit{Publisher/Subscriber pattern}. This is evident in how the \texttt{Flow<T>} interface is implemented. The data source implementation for a \texttt{Flow<T>} is done using a builder, and the initiation of the flow sequence is triggered by the \texttt{Flow.collect()} method.

Hot flows in Kotlin are represented by the \texttt{SharedFlow<out T> : Flow<T>} interface. Unlike \texttt{Flow<T>}, which initiates a flow every time \texttt{Flow.collect()} is called, \texttt{SharedFlow.collect()} emits an unpredictable set of items from an external stream of events initiated before the call to \texttt{SharedFlow.collect()}. 

Kotlin's \texttt{Flow<T>} provides a fluent API of intermediate operators that allow data transformation through operation pipelines, similar to what we have already seen in RxJava and Project Reactor. 

A \texttt{Flow<T>} data source implementation is done through a builder, like we can see in the next example:


\begin{center}
	\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
	\begin{lstlisting}[
		escapeinside={(*}{*)},
			caption={Flow builder},
			language={java},
			label={lst-top5-kotlin}
	]
fun simple(): Flow<Int> = flow { // flow builder
for (i in 1..3) {
	delay(100) // pretend we are doing something useful here
	emit(i) // emit next value
}
}

fun main() = runBlocking<Unit> {
launch {
	for (k in 1..3) {
		println("I'm not blocked $k")
		delay(100)
	}
}
simple().collect { value -> println(value) } 
}

//output:
//I'm not blocked 1
//1
//I'm not blocked 2
//2
//I'm not blocked 3
//3
	
	\end{lstlisting}
\end{center}


A consumer, to start listening a particular data flow haves to call the method \texttt{Flow.collect()}\\. Since \texttt{Flow} provides support only to cold flows, calling \texttt{collect()} has the particularity of initiating flow the sequence.
On the other side, Hot flows in Kotlin are represented by the interface \texttt{SharedFlow<out T> : Flow<T>}. 

The main difference between the implementation of these two interfaces, is at the result of \texttt{collect()} call. 
While the \texttt{Flow.collect()} starts the flow every time its called, resulting in the limited emission of the same set of items per call; the \texttt{SharedFlow.collect()} emits an unpredicted set of items from external stream of events initiated before the call to \texttt{SharedFlow.collect()}.
On the other side, while the \texttt{Flow.collect()} call context is private to the caller, the \texttt{ShareFlow.collect()} is shareable by N subscribers, which makes this solution ideal for broadcast mechanisms shared by many users.
On the next example, we can see several calls to the \texttt{Flow.collect()} that results in retrieving the same set of items; as explained, the call starts a cold flow every time its called:

\begin{center}
	\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
	\begin{lstlisting}[
		escapeinside={(*}{*)},
			caption={Kotlin collect multicall example},
			language={java},
			label={lst-top5-kotlin-cold}
	]
fun simple(): Flow<Int> = flow { 
	println("Flow started")
	for (i in 1..3) {
		delay(100)
		emit(i)
	}
}

fun main() = runBlocking<Unit> {
	println("Calling simple function...")
	val flow = simple()
	println("Calling collect...")
	flow.collect { value -> println(value) } 
	println("Calling collect again...")
	flow.collect { value -> println(value) } 
}

//Output:
//Calling simple function...
//Calling collect...
//Flow started
//1
//2
//3
//Calling collect again...
//Flow started
//1
//2
//3
	
	\end{lstlisting}
\end{center}

As we can see, with the use of the keyword \textit{emit}, it is achieved the same of what we saw in C\# with the use of the keyword \texttt{yield return}.
In this case, the same way the \textit{yield return} returned an item that was part of an asynchronous enumeration of events through \texttt{IAsyncEnumerable}, the use of the keyword \textit{emit} will lazily emit data, as it becomes available to be set as event of the Flow.

Likewise what happens in RxJava, \texttt{Flow<T>} provides a fluent API of intermediate operators that allow data transformation through the use of operation pipelines, where is received an upstream  flow and the operators return a transformed downstream flow through the traditional push methods like: filter, map(), zip(),take() etc... 
On the next example, we can see an example of an asynchronous data pipeline operation from Kotlin \texttt{Flow<T>}, taking advantage of the Fluent API provided by its platform:

\begin{center}
	\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
	\begin{lstlisting}[
		escapeinside={(*}{*)},
			caption={Kotlin collect multicall example},
			language={java},
			label={lst-top5-kotlin-cold}
	]
suspend fun performRequest(request: Int): String {
	delay(1000) // imitate long-running asynchronous work
	return "response $request"
}

fun main() = runBlocking<Unit> {
	(1..3).asFlow() // a flow of requests
		.map { request -> performRequest(request) }
		.collect { response -> println(response) }
}

//Output:
//response 1
//response 2
//response 3
	
	\end{lstlisting}
\end{center}


\subsection {.NET C sharp}
\label{sec:csharp}


\subsubsection{RxNet}
\label{rxnet}

RxNet is the .NET implementation of the ReactiveX project, providing the same powerful programming paradigm from ReactiveX to the .NET ecosystem. This implementation allows developers in the .NET framework to effectively manage asynchronous data flow using the Observer pattern and functional programming techniques, as explained in the ReactiveX and RxJava sections.

In the context of C\#, the concepts of Observables and Observers (or Subscribers) are represented by the \texttt{IObservable<T>} and \texttt{IObserver<T>} interfaces. These are analogous to the \texttt{IEnumerable<T>} and \texttt{IEnumerator<T>} interfaces in the synchronous realm, and closely resemble the implementations seen in RxJava.

Therefore, the understanding and application of RxNet would follow the same principles and design patterns as observed in RxJava. The key advantage of RxNet is that it provides .NET developers with an abstracted and simplified approach to asynchronous programming, similar to what the ReactiveX project offers in other languages.

Importantly, RxNet is fully integrated with other .NET asynchronous programming constructs such as Tasks and the async/await pattern, offering a robust and comprehensive toolset for addressing various asynchronous and event-based programming scenarios in the .NET framework.

\subsubsection{Asynchronous Enumerables}
\label{csenums}
In the .NET framework, the concept of an enumerable is represented through the \texttt{IEnumerable<T>} interface, which defines a method \texttt{GetEnumerator()}. This method returns an \texttt{IEnumerator<T>}, enabling iteration over a collection. To extend this concept to the asynchronous world, .NET introduces the \texttt{IAsyncEnumerable<T>} interface.

Similar to its synchronous counterpart, \texttt{IAsyncEnumerable<T>} returns an \texttt{IAsyncEnumerator<T>}, but with an asynchronous \texttt{MoveNextAsync()} method. This minor but significant modification lets us deal with data sources where data availability is asynchronous, such as real-time feeds, network streams, etc.

Here's a simple example of how asynchronous enumerables can be used in C\#:

\begin{center}
	\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
	\begin{lstlisting}[
		escapeinside={(*}{*)},
			caption={Asynchronous Enumerable, C\# example},
			label={lst-top5-dotnetasenum}
	]
static async Task Main(string[] args)
{
IAsyncEnumerable<int> enumerable = FetchItems(1000);
int i = 0;
await foreach (int item in enumerable)
{
	if (i++ == 10){ break;}
	Console.WriteLine(item);
}
}

static async IAsyncEnumerable<int> FetchItems(int delay)
{
int count = 0;
while(true)
{
	await Task.Delay(delay);
	yield return count++;
}
}
//
//1
//1 sec delay
//2
//1 sec delay
//3
//....
	\end{lstlisting}
\end{center}

This example demonstrates how asynchronous data sources can be worked with in a similar way as synchronous collections, thanks to the use of \texttt{IAsyncEnumerable<T>} and the \texttt{await foreach} construct.

\subsection{Javascript}
\label{jsae}

As a functional and dynamically-typed language, JavaScript provides a distinctive approach to managing asynchronous data flow. Enabled by its asynchronous runtime environment, Node.js, JavaScript employs specific intrinsic keywords and libraries to facilitate asynchronous operations. JavaScript's native constructs, namely the \texttt{async...await} and \texttt{for await...of} keywords, significantly ease the handling of asynchronous tasks. Beyond these built-in facilities, libraries like the Reactive Extensions for JavaScript (RxJS) enhance these capabilities further, enabling more sophisticated operations on asynchronous data streams. This section explores both JavaScript's intrinsic keywords and the RxJS library, emphasizing their respective roles in handling asynchronous flows in JavaScript.

\subsubsection{Javascript Intrinsic Words: async...await and for await...of}
\label{jsintrin}

The JavaScript runtime environment, Node.js, adopts a functional and weakly-typed approach to asynchronous flow processing. The mechanism to process asynchronous streams is somewhat similar to what we've seen in C\#, but instead uses intrinsic keywords \texttt{async...await} and \texttt{for await...of}.

The keyword pair \texttt{async...await} provides a syntax that closely resembles synchronous code while making asynchronous calls. The \texttt{async} keyword marks a function as asynchronous and enables the use of the \texttt{await} keyword within it. The \texttt{await} keyword is then used before calling an asynchronous function, indicating that the function should pause and wait for the Promise to resolve or reject.

On the other hand, the keywords \texttt{for await...of} provide support for iterating over asynchronous enumerables, as demonstrated in the following example:

\begin{center}
	\lstset{basicstyle=\scriptsize\ttfamily,frame=bottomline}
	\centering
	\begin{lstlisting}[
	escapeinside={(}{)},
	caption={Mozilla's Javascript Asynchronous Enumerables example},
	label={lst-top5-js-async-enum}
	]
	async function* streamAsyncIterable(stream) {
	const reader = stream.getReader();
	try {
	while (true) {
	const { done, value } = await reader.read();
	if (done) {
	return;
	}
	yield value;
	}
	} finally {
	reader.releaseLock();
	}
	}
	
	async function getResponseSize(url) {
	const response = await fetch(url);
	let responseSize = 0;
		
		const iterable = streamAsyncIterable(response.body);
		
		for await (const chunk of iterable) {
			responseSize += chunk.length;
		}
		return responseSize;
	}  
		\end{lstlisting}
	\end{center}

This example demonstrates how JavaScript's \texttt{async function*} construct can be used to define asynchronous enumerables. These can then be conveniently iterated over using the \texttt{for await...of} construct, just like you would with regular collections.


\subsubsection{RxJS}
\label{rxjs}

RxJS represents the JavaScript adaptation of the ReactiveX project, analogous to RxNet in .NET and RxJava in Java. This library furnishes JavaScript developers with the same robust mechanisms and abstractions for handling asynchronous data streams. 

While RxJS operates under similar principles as its Java and .NET counterparts, it introduces unique approaches that cater specifically to JavaScript's dynamic and functional nature. As such, the core philosophy remains consistent across these libraries: simplifying the management of asynchronous data streams, with specific implementations nuanced to suit the distinct characteristics of their respective languages.


\subsubsection{IxJS - Interactive Extensions for JavaScript}
\label{ixjs}

IxJS, also known as Interactive Extensions for JavaScript, is an integral part of the ReactiveX project and aims primary to enable the manipulation of data sequences, similarly to RxJS.

Similarly with another technologies already studied in this work, IxJS focuses on providing powerful abstractions for managing both synchronous and asynchronous sequences of data, while also aiming to be approachable and understandable. It has a robust suite of operators that you can use to write expressive, declarative code. 
Developers can also create custom operators very easily, extending the core functionality of IxJS to suit specific needs.


\subsection{Technologies comparison}
\label{sec:tech_compare}

As we saw, each technology have a set of properties that help to characterize the solution.
To help the characterization of each technology documented, we have a relation between the characteristics saw in the chapter \ref{sec:async_concepts}.


\begin{table}[H]
	\begin{tabular}{|c|c|c|c|c|c|}
	\hline
	 & \textbf{Rx(JAVA/.NET)} & \textbf{FLUX} & \textbf{FLOW} & \textbf{C\# async enums} & \textbf{IxJS} \\ \hline
	\textbf{Pull} &  & x & x & x & x\\ \hline
	\textbf{Push} & x & x &  &  & \\ \hline
	\textbf{Cancelable} & x & x & x & x & x \\ \hline
	\textbf{Error Handling} & x & x & x & x & x\\ \hline
	\textbf{Backpressure} & x & x & x & & \\ \hline
	\textbf{Intrinsic words} & & & x & x & x\\ \hline
	\end{tabular}
\end{table}
